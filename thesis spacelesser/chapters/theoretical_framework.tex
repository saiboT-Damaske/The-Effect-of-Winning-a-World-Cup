This section presents the theoretical foundations of the causal inference methods used in this thesis. I begin with the potential outcomes framework for treatment effect estimation, then discuss event studies and synthetic difference-in-differences - the two main approaches employed in both \citet{Mello2024} and this replication.

\subsection{The Potential Outcomes Framework}

The fundamental goal of causal inference is to estimate the effect of a treatment on an outcome. Following the potential outcomes framework formalized by \citet{Rubin1974}, each unit $i$ has two potential outcomes: $Y_i(1)$ under treatment and $Y_i(0)$ under control. Since each unit is observed in only one state -- the ``fundamental problem of causal inference'' \citep{Holland1986} -- individual treatment effects $\tau_i = Y_i(1) - Y_i(0)$ are not directly identified.

The average treatment effect (ATE) is defined as:
\begin{equation}
\tau^{ATE} = E[Y_i(1) - Y_i(0)]
\label{eq:ate}
\end{equation}

In observational settings with panel data and staggered treatment adoption, such as World Cup victories occurring at different times for different countries, the estimate of interest is typically the average treatment effect on the treated (ATT):
\begin{equation}
\tau^{ATT} = E[Y_i(1) - Y_i(0) \mid D_i = 1]
\label{eq:att}
\end{equation}
which measures the effect specifically for units that received treatment, i.e. winners of a FIFA World Cup. This is the quantity estimated by both the event study and SDID approaches in this thesis.

\subsection{Event Study Design}

The event study methodology estimates dynamic treatment effects by comparing outcomes at different points in time relative to an event. Originally developed in finance to study stock price reactions \citep{Fama1969}, the approach has become standard for analyzing policy changes, economic shocks, and discrete interventions in panel data settings \citep{Angrist2009}.

Let us consider a balanced panel of $N$ units (countries) over $T$ periods (quarters), where unit $i$ receives treatment at time $E_i$. The relative time to treatment is $K_{it} = t - E_i$, such that the indicator $\mathbf{1}[K_{it} = k]$ equals one when unit $i$ is exactly $k$ periods from its treatment date. The event study specification is:
\begin{equation}
Y_{it} = \alpha_i + \lambda_t + \sum_{k \neq k^*} \beta_k \cdot \mathbf{1}[K_{it} = k] + X_{it}'\gamma + \varepsilon_{it}
\label{eq:event_study}
\end{equation}
where $\alpha_i$ are unit fixed effects absorbing time-invariant country characteristics, $\lambda_t$ are time fixed effects absorbing common shocks affecting all countries, $X_{it}$ are time-varying controls, and one relative time period $k^*$ is omitted as reference (typically $k^* = -1$, the period before treatment). The coefficients $\beta_k$ estimate the average effect at horizon $k$ relative to the reference period.

\subsubsection{Identification Assumptions}

Event study identification rests on two key assumptions.

\textbf{Parallel trends:} Absent treatment, treated and control units would follow parallel outcome paths. Formally,
\begin{equation}
E[Y_{it}(0) - Y_{i,t-1}(0) \mid D_i = 1] = E[Y_{it}(0) - Y_{i,t-1}(0) \mid D_i = 0]
\label{eq:parallel_trends}
\end{equation}

\textbf{No anticipation:} Treatment does not affect outcomes before it occurs,
\begin{equation}
Y_{it}(1) = Y_{it}(0) \quad \text{for all } t < E_i
\label{eq:no_anticipation}
\end{equation}

The pre-treatment coefficients $\{\beta_k : k < 0\}$ provide a testable implication that under these assumptions, they should be statistically indistinguishable from zero. A flat pre-trend supports the parallel trends assumption, though it cannot definitively prove it.

\subsubsection{Challenges with Heterogeneous Treatment Effects}

There exist potential problems with two-way fixed effects (TWFE) estimators -- regressions that include both unit- and time fixed effects -- when treatment occurs at different times for different units. The issue arises because TWFE implicitly constructs comparisons between all groups, not just treated versus never-treated. Suppose that Germany wins in 1974 and Italy wins in 1982. To estimate the effect of winning, TWFE compares winners against never-winners (a valid comparison), but it also compares Italy (newly treated in 1982) against Germany (already treated in 1974). The second comparison treats Germany as a ``control'' after it has already won -- if winning has persistent effects, this comparison is contaminated.

\citet{Goodman-Bacon2021} formalizes this intuition by showing that the TWFE estimator $\hat{\beta}^{TWFE}$ can be decomposed as a weighted average of all such pairwise comparisons:
\begin{equation}
\hat{\beta}^{TWFE} = \sum_{k} w_k \cdot \hat{\beta}_k
\label{eq:goodman_bacon}
\end{equation}
where $\hat{\beta}_k$ are treatment effect estimates from different $2 \times 2$ comparisons (early vs.\ late treated, treated vs.\ never-treated, etc.) and $w_k$ are data-dependent weights. Crucially, these weights can be negative when already-treated units serve as controls. When treatment effects vary across cohorts or fade over time, these problematic comparisons can bias the overall estimate.

For the World Cup application, these concerns are not handled by Mello and are mitigated by several features: (1) there are relatively few treated units (10 World Cup winners from 1966--2018; see Section~\ref{data} for details), (2) treatment effects are expected to be transitory, meaning already-treated units return to baseline before serving as controls, and (3) I have a large pool of never-treated OECD countries providing clean comparisons. Importantly, I complement the event study with SDID to provide converging evidence: while the event study reveals the dynamic pattern of effects over time, SDID constructs an explicit synthetic counterfactual that does not rely on the parallel trends assumption holding globally. When both approaches yield consistent results, confidence in the causal interpretation is strengthened.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Synthetic Difference-in-Differences}

Synthetic difference-in-differences (SDID), proposed by \citet{Arkhangelsky2021}, combines the strengths of synthetic control methods with difference-in-differences logic. While standard DiD assumes parallel trends hold globally, and synthetic control requires exact pre-treatment matching, SDID relaxes both requirements by constructing optimal weights for both units and time periods. This flexibility makes it particularly valuable when pre-treatment trajectories may not be perfectly parallel -- a realistic concern when comparing GDP growth across heterogeneous economies.

Figure~\ref{fig:sdid_comparison} illustrates the intuition behind SDID by comparing three approaches using the canonical California tobacco control example from \citet{Abadie2010}.

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{sdid_comparison.png}
\caption[Comparison of DID, synthetic control, and SDID]{Comparison of difference-in-differences (DID), synthetic control (SC), and synthetic difference-in-differences (SDID). In DID, the treatment effect is estimated as the difference between the treated unit's post-treatment outcome and a simple average of control units. In SC, unit weights are optimized to match the pre-treatment trajectory exactly. SDID combines both: unit weights create a synthetic control while time weights emphasize periods most predictive of post-treatment outcomes. Adapted from \citet{Arkhangelsky2021}.}
\label{fig:sdid_comparison}
\end{figure}

\subsubsection{The SDID Estimator}

Consider a panel with $N$ units observed over $T$ periods, where treated units receive treatment after period $T_0$. Let $W_{it}$ be a treatment indicator equal to one for treated units in post-treatment periods. The SDID estimator solves a weighted two-way fixed effects regression:
\begin{equation}
(\hat{\tau}^{SDID}, \hat{\mu}, \hat{\alpha}, \hat{\beta}) = \argmin_{\tau, \mu, \alpha, \beta} \sum_{i=1}^{N} \sum_{t=1}^{T} \left( Y_{it} - \mu - \alpha_i - \beta_t - W_{it}\tau \right)^2 \hat{\omega}_i \hat{\lambda}_t
\label{eq:sdid_problem}
\end{equation}
where $\hat{\omega}_i$ are unit weights and $\hat{\lambda}_t$ are time weights. The key innovation in comparison to Standard DID is that these weights are chosen to make treated and control units comparable, rather than assuming comparability a priori.

The unit weights are constructed by solving a regularized optimization that matches the pre-treatment trajectory of treated units:
\begin{equation}
\hat{\omega} = \argmin_{\omega \geq 0, \sum_j \omega_j = 1} \sum_{t=1}^{T_0} \left( \bar{Y}_{tr,t} - \sum_{j \in \mathcal{C}} \omega_j Y_{j,t} \right)^2 + \zeta^2 T_0 \|\omega\|_2^2
\label{eq:sdid_unit_weights}
\end{equation}
where $\bar{Y}_{tr,t}$ is the average outcome for treated units at time $t$, $\mathcal{C}$ denotes the set of control units, and $\zeta$ is a regularization parameter that prevents overfitting when the control pool is large. Time weights $\hat{\lambda}_t$ are constructed analogously to identify pre-treatment periods most predictive of post-treatment outcomes.

Given these weights, the SDID treatment effect estimate takes a transparent double-difference form:
\begin{equation}
\hat{\tau}^{SDID} = \underbrace{\left( \bar{Y}_{tr,post} - \bar{Y}_{tr,pre}^{\lambda} \right)}_{\text{treated: post minus weighted pre}} - \underbrace{\sum_{j \in \mathcal{C}} \hat{\omega}_j \left( \bar{Y}_{j,post} - \bar{Y}_{j,pre}^{\lambda} \right)}_{\text{synthetic control: post minus weighted pre}}
\label{eq:sdid_att}
\end{equation}
where $\bar{Y}_{tr,pre}^{\lambda} = \sum_{t=1}^{T_0} \hat{\lambda}_t \bar{Y}_{tr,t}$ is the weighted pre-treatment average for treated units. This expression shows that SDID estimates the ATT by comparing pre-to-post changes for treated units against pre-to-post changes for a synthetic control constructed from weighted donor units.

\subsubsection{Identification Assumptions}

Like the event study, SDID requires assumptions for the estimated ATT to have a causal interpretation.

\textbf{No anticipation:} Treatment does not affect outcomes before it occurs -- the same condition as in Equation~\eqref{eq:no_anticipation}. For the World Cup setting, this means that winning does not influence GDP growth before the tournament has taken place.

\textbf{Overlap (common support):} The control pool must be rich enough to approximate the treated unit's pre-treatment trajectory through a weighted combination. Formally, the weighted synthetic control $\sum_{j \in \mathcal{C}} \hat{\omega}_j Y_{j,t}$ must be able to track $\bar{Y}_{tr,t}$ during the pre-treatment window. With an average of 45 OECD countries in the donor pool per World Cup, this condition is comfortably satisfied.

\textbf{Weak dependence of errors:} The idiosyncratic shocks $\varepsilon_{it}$ must be weakly dependent over time with bounded moments \citep{Arkhangelsky2021}. This rules out highly persistent or explosive error processes but is standard for quarterly GDP growth data.

A key advantage of SDID over standard DiD is its \textit{double robustness}: the estimator remains consistent if either parallel trends hold globally \textit{or} the unit weights successfully match the treated unit's pre-treatment path. This means that even if the unweighted control countries follow a different growth trajectory than the winner, the ATT is still identified as long as the synthetic control constructed from the weighted donors tracks the winner closely before the World Cup.

\subsubsection{Properties and Inference}

\citet{Arkhangelsky2021} establish that under the conditions above, the SDID estimator is consistent and asymptotically normal. In practice, inference relies on bootstrap methods that resample at the unit level, preserving within-unit serial correlation. Following \citet{Mello2024}, I use 1,000 bootstrap replications with standard errors clustered at the country-subseries level.

SDID is well-suited for the World Cup setting because it can construct tailored counterfactuals for each of the winner countries by optimally weighting the control/never-winning OECD countries according to their pre-victory trajectories. 